\section{Results and Implications}
We begin by examining the use case to develop hypotheses from a domain-knowledge perspective. These hypotheses are then tested using selected xAI methods. Additionally, we discuss the advantages and disadvantages of the chosen methods. Based on our findings, we propose an adapted workflow and outline the limitations of our process, offering directions for future research. The workflow stems from the approach by \citeA{tchuente2024methodological} and is inspired by their phases Idea, Data and Context.

\subsection{Initial Exploration of the Use Case}
To develop a basis for comprehensible and expertise-based hypotheses, an analysis must be carried out in the specific domain. For this, we analyze the data using an exploratory data analysis \shortcite{tukey1977exploratory}. The chosen action of the agent can be considered the dependent variable in our dataset, while we treat the other variables as features.

\subsubsection{Most manufactured Products}
Product 5 was produced the most, followed by product 8, then product 1. Product 7 was produced the least (Fig \ref{fig:Produced_aggs}). The most produced product 5 appeared more than five times as often as the second most produced product 8. The dataset is thus imbalanced regarding product 5 (the dependent variable).

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\linewidth]{pictures/product_count.png}
    \caption{Bar plot of the total amount of products that were produced. Product five has been produced the most. Some products have not been produced at all in the given dataset.}
    \label{fig:Produced_aggs}
\end{figure}

A potential thesis to draw here is that the variables concerning the products that were produced should play a more important role in the xAI methods than the ones concerning those products that were not produced. Variables relating to products that were not produced may still be part of the reasoning for the agent to make a production decision. However, the reason why certain products were produced should be reflected in the importance of the variables concerning these products, due to the domain-specific objectives (e.g., products are produced when there is demand). If an product was produced but none of the variables relating to its demand and buffer seem to play a role, there might be an underlying logical issue.

\subsubsection{Last Product Type}
The last product type feature is a dummy encoded variable (0 or 1) indicating if the predecessor is the same product as produced before. For instance, if \texttt{last\_prod\_type\_is\_prod5} equals 1, the product produced one step before was product 5. It thus encodes the ordering of the products (Fig. \ref{fig:order}). Product 5 has been produced first followed by short periods of products 8 and 7. Product 1 also breaks the production cycle of product 5 at index 50. Product 8 is being produced again a second time at the end.


\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{pictures/order_succession.png}
    \caption{Order of produced product lots. The x-axis shows the order of the products. Product 5's production has been interrupted three times. 33 lots of product 5 have been produced uninterruptedly. This is the longest unbroken sequence.}
    \label{fig:order}
\end{figure}

Besides avoiding idle times in the FAS, the second objective of the agent is to minimize setup efforts in the PAS. Both have to be balanced out, even though idle times are slightly prioritized. As a consequence, we should see that the agent does not constantly change between production of products (unless that is necessary due to an empty buffer or wrong buffer content), which would lead to sequence depended setup efforts.
We see that this is the case for product 1 and product 7; however, the agent produces product 5 and product 8 with breaks in between. Here, the other main objective of the agent – to avoid high criticality and keep a safety margin – should be of relevance. In certain cases, the agent might need to switch between production of products (at the cost of increasing setup efforts), if criticality of another product is too high.

The insight derived from this is that a) because of the objective of minimizing setup efforts \texttt{last\_prod\_type\_is\_prodX} = 1 increases the probability that the same product will be produced again. However, b) if the criticality of another product is high, the agent switches to producing this product and \texttt{last\_prod\_type\_is\_prodX} = 1 of the current product \texttt{X} will lower the probability of it being produced again (see Table \ref{tab:criticality_analysis}). The objective of avoiding criticality is then of bigger concern than minimizing setup efforts.
If both are relevant at the same time, the effects can be contradictory. For example, minimizing setup efforts will lead to production, even when there is low criticality. High criticality in contrast will interfere with minimizing setup efforts.

\subsubsection{Buffer Fill Level}
Since the PAS and the FAS are connected via a limited buffer, the buffer acts as a bottleneck that constrains the material flow.
The buffer fill level increases over time (Fig. \ref{fig:buffer_fill_level}). This is intuitive, since the agent causes products to be produced and the PAS has a higher throughput than the FAS. This effect becomes particularly significant later in the planning period.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\linewidth]{pictures/buffer_fill_level.png}
    \caption{The buffer fill level over 113 decisions of the agent. After index 50 there is a clear upward trend. The trend line has been fitted with a locally weighted liner regression model (\texttt{frac = 0.66}). Note that the y-axis starts at 0.75. Reason: The throughput of the FAS decreases from index 60, so that the PAS fills the buffer with future relevant products. The critical phase in which utilization and setup efforts are balanced are therefore up to around index 60.
    }
    \label{fig:buffer_fill_level}
\end{figure}

\subsubsection{Buffer Fill Level of the Specific Products}
To gain knowledge about specific products, the role of the buffer has to be examined for these product types. The following plot shows the mean buffer content for all products over the whole trajectory (Fig. \ref{fig:buffer_for_aggs}).

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{pictures/buffer_content.png}
    \caption{Mean buffer content duration for products. The vertical lines show standard deviations.}
    \label{fig:buffer_for_aggs}
\end{figure}

Utilizing this feature, we can interpret the production of these products.
The products that were \textit{not} produced (2, 3, 4, 6) had a mainly full mean buffer. Since the buffer satisfies the demand, products with a full buffer were not produced. The product types that were produced had a lower mean buffer and more deviation overall. In fact, product 5 – produced the most – had the lowest mean buffer. Here, it is important to highlight that the agent tries to keep a sufficient level in buffer for all product types to maintain the safety margin and avoid criticality. Therefore, it is plausible to assume that those products with a low buffer fill level are produced more often. Vice versa, if the \texttt{buffer\_content\_duration} of a given product is high, it is more unlikely that this product will be produced. However, this only accounts for criticality. When considering setup efforts the effect can be reversed. The probability of producing an product can increase although the \texttt{buffer\_content\_duration} of this product is already high to minimize setup efforts. Thus, the criticality and setup efforts hypotheses may be of relevance simultaneously and their effects can overlap.

\subsubsection{Demand}
Demand is encoded in two features, \texttt{next\_24h\_demand} and \texttt{end\_of\_planning\_period\_demand}. The adjoining table summarizes these:

\begin{table}[ht!]
    \footnotesize
    \centering
    \caption{The mean demand for the products. * = produced}
    \label{t:demand_agg}
    \begin{tabularx}{\textwidth}{lXX}
        \toprule
        \textbf{Product} & \textbf{next\_24h\_demand} & \textbf{end\_of\_planning\_period\_demand} \\
        \midrule
        1*               & 0.002636                   & 0.068180                                   \\
        2                & 0.000000                   & 0.000250                                   \\
        3                & 0.000000                   & 0.000000                                   \\
        4                & 0.000000                   & 0.000000                                   \\
        5*               & 0.063485                   & 1.000000                                   \\
        6                & 0.000000                   & 0.000000                                   \\
        7*               & 0.013801                   & 0.330981                                   \\
        8*               & 0.041675                   & 0.857493                                   \\
        \bottomrule
    \end{tabularx}
\end{table}
\FloatBarrier

It is important to note that both demand types, \texttt{next\_24h\_demand} and \texttt{end\_of\_planning\_period\_demand}, show the demand left after considering the amount of demand the buffer can satisfy. Therefore, a logical conclusion is that if the buffer for an product increases the demand should decrease.
Since the 24h demand is more urgent in a manufacturing environment, those products with a higher \texttt{next\_24h\_demand} should be more likely to be produced. In fact, we see in Table \ref{t:demand_agg} that only those products with a 24h demand were produced at all. Product 5 with the highest mean demand (both types) was produced the most.

The conclusion to be derived from this is that net demand (after deducting the buffer) of an product is positively associated with its production. However, if no product is critical, the agent can continue to produce an product with low demand to minimize setup efforts. Additionally, demand of other products can also influence if an product with high demand is produced. If the demand of another product is higher, a high demand of the product being produced in the instance can make it more unlikely that it is being produced again, because the criticality of another product is higher and the agent has to switch to producing this product.

\subsubsection{Criticality}
\label{criticality_chapter}
Criticality \( C \) is defined as:

\[
    C = \frac{\texttt{next\_24h\_demand}}{\texttt{buffer\_content\_duration}},\]

where \(\texttt{buffer\_content\_duration} > 0\). Increasing criticality is linked to increasing demand and decreasing buffer content of an product. Criticality is implicitly present in the data, but not explicitly as a feature. We assume that the NN was able to learn this non-linear relationship \shortcite{bengiononlinear}.

\subsection{Generating Hypotheses}
The hypotheses to be derived using domain knowledge (RQ 1.1), descriptive statistics and the objectives of the agent can be subsumed under the two parts of the agent's reward function.

\textbf{Criticality}:
High criticality is characterized by high net demand and low buffer content, which is a state the agent tries to avoid, because it increases risk of idle times.
Therefore, a high net demand and/or low \texttt{buffer\_content\_duration} of one of the produced products in the data should be positively associated with production in the xAI methods and vice versa. However, if the demand of the\textit{ successing }product is higher and/or the buffer is lower, the agent should switch to that product and \texttt{last\_prod\_type} = 1, a higher demand and/or lower\textit{ }buffer of the current product will speak \textit{against} it being produced again.
In Table \ref{tab:criticality_analysis}, the criticality for product 5 is zero (the demand is zero and the buffer is halfway full (0.522), but the criticality for product 8 is greater than 1 (there is demand and the buffer content is low). Therefore, the agent switches from producing product 5 to product 8 in the second action.

\textbf{Setup Efforts}:
The agent tries to minimize setup efforts, which is indicated by the \texttt{last\_prod\_type} dummy variable. If an product was produced already (\texttt{last\_prod\_type} = 1), it should increase the probability that the same product will be produced again. This however can lead to a trend that speaks against the hypothesis implied by criticality: The probability of producing an product may increase, although the buffer of this product is high and the demand is low. This can happen, when no other product is critical; therefore, the agent sticks to the production of one product to minimize setup efforts.
If we find the reversed trend and \texttt{last\_prod\_type} = 1 decreases the probability that the product is produced again, this should correspond with high criticality – the first objective of the agent – for a different product that is then produced in the next instance.

\begin{table}[ht!]
    \footnotesize
    \centering
    \caption{Criticality Analysis}
    \label{tab:criticality_analysis}
    \begin{tabularx}{\textwidth}{lXr}
        \toprule
        \textbf{Product}   & \textbf{Metric}                  & \textbf{Value} \\
        \midrule
        Product 5          & Criticality                      & 0              \\
                           & 24h\_demand                      & 0              \\
                           & buffer\_duration                 & 0.522          \\
                           & last\_prod\_is\_prod\_5          & 1.0            \\
        \midrule
        \textbf{Product 8} & \textbf{Criticality}             & \textbf{1.098} \\
                           & \textbf{24h\_demand}             & \textbf{0.191} \\
                           & \textbf{buffer\_duration}        & \textbf{0.174} \\
                           & \textbf{last\_prod\_is\_prod\_5} & \textbf{0}     \\
        \midrule
        Product 8          & Criticality                      & 0.875          \\
                           & 24h\_demand                      & 0.175          \\
                           & buffer\_duration                 & 0.200          \\
                           & last\_prod\_is\_prod\_8          & 1.0            \\
        \midrule
        Product 8          & Criticality                      & 0.716          \\
                           & 24h\_demand                      & 0.159          \\
                           & buffer\_duration                 & 0.222          \\
                           & last\_prod\_is\_prod\_8          & 1.0            \\

        \bottomrule
    \end{tabularx}
\end{table}
\FloatBarrier


\begin{table}[ht!]
    \footnotesize
    \centering
    \caption{Setup-efforts Analysis}
    \label{tab:setup_efforts_analysis}
    \begin{tabularx}{\textwidth}{lXr}
        \toprule
        \textbf{Product} & \textbf{Metric}                  & \textbf{Value} \\
        \midrule
        Product 5        & Criticality                      & 0.887          \\
                         & 24h\_demand                      & 0.268          \\
                         & buffer\_duration                 & 0.302          \\
                         & \textbf{last\_prod\_is\_prod\_5} & \textbf{1.0}   \\
        \midrule
        Product 5        & Criticality                      & 0.784          \\
                         & 24h\_demand                      & 0.243          \\
                         & buffer\_duration                 & 0.310          \\
                         & \textbf{last\_prod\_is\_prod\_5} & \textbf{1.0}   \\
        \midrule
        Product 5        & Criticality                      & 0.735          \\
                         & 24h\_demand                      & 0.228          \\
                         & buffer\_duration                 & 0.310          \\
                         & \textbf{last\_prod\_is\_prod\_5} & \textbf{1.0}   \\
        \midrule
        Product 5        & Criticality                      & 0.732          \\
                         & 24h\_demand                      & 0.227          \\
                         & buffer\_duration                 & 0.310          \\
                         & \textbf{last\_prod\_is\_prod\_5} & \textbf{1.0}   \\
        \bottomrule
    \end{tabularx}
\end{table}
\FloatBarrier

These two tables illustrate both objectives of the agent with examples from production.
In Table \ref{tab:criticality_analysis}, we can see that product 8 is critical (in bold), because there is demand for this product, but the buffer content is low. The agent then switches from producing product 5 with zero criticality to production of this product.
In Table \ref{tab:setup_efforts_analysis}, setup efforts are minimized by sticking to the production of the same product, which is indicated by the last product type always being the same (in bold).

As both tables suggest, the hypotheses need to be tested with the produced products, taking all features into account (RQ 1.1) and embedding the complete production scenario. We now look at the top ten most important variables and products for both xAI methods. Then, we compare both methods regarding their performance and interpretability. We also apply the hypotheses to the products not produced (see Chapter \ref{Appendix_Notproduced_Aggs}).

\subsection{Applying Hypotheses}
\subsubsection{Product 1}
Product 1 was produced the third most (Fig. \ref{fig:order}). In the order of production, it predecessor and successor product was product 5 which was the most produced product.

Regarding DeepSHAP, we can see that if the last product produced was already product 1, it is more likely that this product will be produced again (Fig. {\ref{fig:SHAP_Action0}}) and vice versa. This aligns with the setup efforts hypothesis. Moreover, a lower buffer content is positively associated with production of the product and vice versa, which matches the criticality hypothesis.
If the last product type was product 5, product 1 is more likely to be produced. This aligns with product 1 only being produced following product 5 in the course of production. The other variables have SHAP values around zero.

Regarding Input X Gradient (Table \ref{tab:variables}), it can be seen that increasing \texttt{buffer\_content\_duration\_prod1} mitigates the production of product 1. This can be taken one step further by observing that a higher buffer content for product 5 supports the production of product 1. This is in line with the criticality hypothesis, because product 5 is less critical based on a full buffer. In the result, product 1 is produced more. If the last product which was produced is product 1 as well, it has a positive impact on the renewed production of this product. Here the setup-efforts hypothesis is confirmed and matches the data that shows that product 1 was produced continuously without a machine retrofitting. If the \texttt{end\_of\_planning\_period\_demand} of product 5 or 8 were increasing, product 1 had slightly less attribution which matches the criticality hypothesis. The demand at the end of the planning period for both product 5 and 8 favoured less production of product 1, but this effect was really low.
Both hypotheses categories are thus supported by Input X Gradient for product 1.

\subsubsection{Product 5}
Product 5 was produced the most (Fig. \ref{fig:order}). Its production was interrupted by the products 8 and 1, so the machines had to be retrofitted.

Regarding DeepSHAP, we can see that if product 5 was produced last, it is more likely to be produced again (Fig. \ref{fig:SHAP_Action4}), which is in line with the setup efforts hypothesis.
A full buffer content of product 1 is positively associated with production of product 5, while an empty buffer of product 1 speaks against production of product 5. This pattern supports the criticality hypothesis, because if product 1 becomes critical (e.g., due to a low buffer content), production of product 5 should be less likely and vice versa, which is what we find here.
In the order of production, product 8 was produced twice following product 5, but product 5 was not produced after product 8. Therefore, it makes sense that the production of product 5 is more likely when product 8 was not previously produced. However, it should be noted that there are two outliers indicating the opposite direction of effect.
Product 1 disrupted production of product 5 once. The pattern of the variable \texttt{last\_prod\_type\_is\_prod1} is similar to the one of product 8. Most of the time, product 5 was not produced after product 1 and as we can see in the SHAP plot, production of product 5 is associated with the previous product not being product 1. However, there are two outliers again.
Fuller buffer content of product 7 speaks for production of product 5 and vice versa. This is again in line with the criticality hypothesis.
Next, we see that if the last product produced was product 7, this speaks against product 5 being produced next. Here, we have to take into account that product 5 was produced the most, product 7 was produced the least. There is only one case in the order of production, where product 5 was produced after product 7; however; in all other cases this was not true. Therefore, the pattern aligns with the course of production.
The other findings in the SHAP plot, all support the criticality hypothesis:
A low buffer content of product 5 is positively associated with production of product 5.
A higher buffer content of product 8 speaks for production of product 5, while a higher 24h-demand of product 8 is negatively associated with production of product 5.
Higher end of planning period demand for product 1 also speak against production of product 5.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\linewidth]{pictures//shap//SHAP_Bilder/SHAP_domainrand_action4.png}
    \caption{SHAP summary plot for action 4.
        Each point represents the local feature attribution value (Shapley value for feature and instance).
        Blue color indicates a low feature value, for binary variables this is 0, red indicates high feature values, for binary variables this is 1. A positive SHAP value is positively associated with the action, a negative SHAP value is negatively associated with the action. The features are displayed based on importance on average with decreasing importance from top to bottom.}
    \label{fig:SHAP_Action4}
\end{figure}

The following table shows the attribution values we received with the Input X Gradient method:

\begin{table}[ht!]
    \footnotesize
    \centering
    \caption{Top 10 Variables for Input X Gradient and Product 5.}
    \label{tab:top_variables_target4}
    \begin{tabularx}{\textwidth}{lXr}
        \toprule
        \textbf{Rank} & \textbf{Variable}                        & \textbf{Value} \\
        \midrule
        1             & buffer\_content\_duration\_prod5         & -0.17          \\
        2             & buffer\_content\_duration\_prod8         & 0.12           \\
        3             & last\_prod\_type\_is\_prod5              & 0.10           \\
        4             & end\_of\_planning\_period\_demand\_prod5 & 0.08           \\
        5             & buffer\_content\_duration\_prod1         & 0.07           \\
        6             & buffer\_content\_duration\_prod6         & -0.06          \\
        7             & next\_24h\_demand\_prod8                 & -0.05          \\
        8             & end\_of\_planning\_period\_demand\_prod8 & -0.04          \\
        9             & buffer\_content\_duration\_prod3         & 0.03           \\
        10            & buffer\_content\_duration\_prod4         & -0.02          \\
        \bottomrule
    \end{tabularx}
\end{table}
\FloatBarrier

If the buffer content was high for product 5, the probability that it was produced again sunk. In addition, if the buffer for product 8 was high, product 5 was produced more often. A plausible conclusion could be that the buffer content was sufficient to satisfy the demand of product 8, thus alleviating criticality. Unsurprisingly, if the last product was product 5 it was more likely that it was produced again (\texttt{last\_prod\_type\_is\_prod5}). The setup efforts hypothesis is thus supported here. The \texttt{end\_of\_planning\_period\_demand\_prod5} also had a positive influence. The machine had to be retrofitted two times for products 1 and 8, high buffer content for these products amongst other effects triggers product 5's production as well. A full buffer signals that product 5 can be produced again (lower criticality of products 1 and 8). Also slightly supporting the criticality hypothesis, a higher demand for product 8 in 24h had a negative attribution for product 5.

Both hypotheses are supported thus by Input x Gradient for product 5.

\subsubsection{Product 7}
Product 7 was produced the least. The predecessor of product 7 was
product 8, the successor product 5.

Regarding SHAP (see Fig. \ref{fig:SHAP_Action6}), we can see that if product 7 was not produced last, production of this product is less likely, which is in line with the setup efforts hypothesis. There is only one individual SHAP point indicating the opposite direction of this hypothesis (i.e., that production of product 7 is positively associated with it being produced again). This makes sense, because descriptively this product was produced only a couple of times, too few cases to create a visual trend in
the plot.
Fuller buffer content of product 7 speaks against its production, which is in line with the criticality hypothesis; however, the SHAP values for the opposite direction of this hypothesis (i.e. less buffer content is associated with more production) are close to zero. Again, there is only one individual point indicating the latter, which might be tied to product 7 being rarely produced. If it was barely ever produced, it is intuitive that there will be only few cases indicating such a direction of effect.
Product 7 was never produced directly after product 5, which aligns with the plot where we can see that if the last product produced was 5, production of product 7 is less likely.
Lower buffer contents of product 8 is negatively associated with production of product 7, in alignment with the criticality hypothesis. However, the SHAP values for the opposite direction of this hypothesis are close to zero.
Fuller buffer contents of product 1 and 5 are positively associated with production
of product 7, in line with the criticality hypothesis. However, again the SHAP values are close to zero.

Regarding Input x Gradient (Table \ref{tab:top_variables_target6}), the attributions were generally low. A higher \texttt{buffer\_content\_duration\_prod\_8} compliments the production of product 7, whereas a higher product 7 buffer speaks against its production. This supports the criticality aspect (see above). Interestingly, the generic buffer fill level has a negative influence on the production of product 7. This may be because of its rare occurrence. In summary Input x Gradient supports the criticality hypothesis.

\subsubsection{Product 8}
Product 8 was produced the second most.

Regarding DeepSHAP, we can see that if product 8 was not produced last, it is less likely to be produced again (Fig. \ref{fig:SHAP_Action7}). This is generally in line with the logic of the setup efforts hypothesis, though it is the reversed pattern (e.g., the product \textit{not} being produced last is associated with it \textit{not} being produced again). Interestingly, for the other direction of effect (e.g., the product being produced last, is associated with it being produced again) there are only few individual SHAP points supporting this trend. This could be related to product 8 batches only being produced thirteen total times, while product 5 was produced more than five times more often. Therefore, it is plausible that the effect is smaller for product 8 than it is for product 5.
Previous production of product 5 is negatively associated with production of product 8, which is in line with production order, because product 5 was produced in the biggest batches without interruption and there are only two cases in total where product 8 was produced after product 5.
Less buffer content duration of product 8 is positively associated with production of product 8, which is in line with criticality hypothesis. Further, a fuller buffer of product 5 (e.g., criticality is low) speaks for production of product 8. Though the SHAP values are small, this matches the criticality hypothesis.
The pattern for buffer content duration of product 1 is ambiguous, but here the SHAP values are close to zero as well
A higher end of planning period demand of product 1 speaks for production of product 8, which might seem unintuitive. Here, it is important to differentiate between the two types of demand in the domain. For criticality, the 24h-demand plays the most important role. This means that the end of planning period demand of an product may be high, but if another product is \textit{more} critical in the next 24h it is going to be produced instead. In this particular case, the variable of buffer content duration of product 8 was higher up in the order of variable importance than end of planning period demand of product 1. This might indicate that product 8 was more critical due to an empty buffer, which is why it was produced; even though, end of planing period demand of product 1 was high.
The other variables have SHAP values around zero.

Regarding Input x Gradient (Table \ref{tab:top_variables_target7}), it can be derived that a higher buffer of product 8 was not supporting further production of product 8 (supporting the criticality hypothesis). If the buffer for product 5 increased in contrast, this supported the production of product 8. Here, the inverse relationship of the criticality hypothesis is visible: If the buffer for product 8 was high, the production of it sunk. If the buffer for product 5 was high, the production of product increased. This can also be seen in the light of the predecessor/successor relation: Product 8 had been uninterruptedly produced for a longer period of time (product 8 was produced after product 5 two times (four times and nine times respectively). The demand of the end of the planning period of product 8 slightly increased the chances of producing product 8. The criticality hypothesis can thus be confirmed, but not with total confidence. The attribution values were too low. Regarding the setup efforts hypothesis, Input x Gradient does not fully support this hypotheses for product 8.

\subsection{Verifying Hypotheses}
Regarding DeepSHAP, we see that the hypotheses of avoiding criticality and minimizing setup efforts hold true both in the patterns for the variables directly related to the produced products and also for the variables concerning the other products.
Input x Gradient supports both hypotheses as well for product 1 and 5. Product 8's attribution values were too low to draw a viable conclusion.

\subsubsection{Variables related to the produced Products}
In DeepSHAP, we can see that if the last product produced was already product 1, product 5, or product 8, it is more likely that these products will be produced again and vice versa, which aligns with minimizing setup times.
A lower buffer content of product 1, product 5, or product 8, is positively associated with production of these products respectively and vice versa, which is in line with the criticality hypothesis.
Due to it rarely being produced, we can also verify the hypotheses for product 7, but only in one direction: If product 7 was not produced last, production of this product is less likely. Fuller buffer content of product 7 speaks against its production.

Input x Gradient also confirms the setup time hypothesis with the feature \texttt{last\_prod\_type\_is\_prodX} for product 1 and 5 but not for product 7 and 8.
Increasing \texttt{buffer\_content\_duration\_prodX} for all four products confirms the criticality aspect as well. A fuller buffer signals lower criticality. The buffer is full and thus it is not critical to produce the product.

\subsubsection{Variables for other Products}
In DeepSHAP, a fuller buffer content of product 1, product 7 or product 8 speak for production of product 5 and vice versa, while a higher demand of product 8 or product 1 speaks against production of product 5. This is in line with the criticality assumption. If the buffer of these products is low or the demand is high and they become critical, product 5 should be less likely to be produced to avoid idle times. However, if they are not critical, the agent should stick to production of product 5 to minimize setup efforts, which is what we see in the plots for product 5.
This pattern holds true for the other classes as well, e.g., a fuller buffer content of product 5 speaks for production of product 8. Lower buffer contents of product 8 is negatively associated with production of product 7.

In the case of Input x Gradient, a full buffer for product 5 supported the production of product 1 (because the buffer of product 5 was high, yielding low criticality for this product). If the demand of product 5 or 8 were increasing, the influence of product 1 decreased, because the criticality of product 5 and 8 increased. The demand at the end of the planning period for both product 5 and 8 favoured less production of product 1, but this effect was low.
For product 5, other features also played an important role. A high buffer content for product 8 supported the production of product 5, because the criticality of product 8 sunk. This holds true for the products 1 and 6 as well. Also slightly supporting criticality, a higher demand for product 8 in 24h had a negative influence on the production of product 5.
For product 8, fuller buffer content for product 5 supported the production of product 8. Again, because the criticality of product 5 sunk. If the last product was product 5, the probability that product 8 was produced sunk slightly. Note that product 8 was not produced perpetually and was interrupted by product 7. It also was produced after 33 products of 5 were produced, so the machine was retrofitted at the end.
For product 7 - the least produced one - we see the criticality hypothesis confirmed because of a higher buffer content of its predecessor product 8. Analogous, a higher buffer for the buffer of 7 itself lowers the probability that it is produced again.

In summary, the overall patterns in the DeepSHAP plots match our hypotheses. Considering Input x Gradient, in the case of product 1 the setup effort hypothesis can be confirmed because there it uninterrupted production. The criticality hypothesis is confirmed as well.
For product 5, both hypotheses can be confirmed again. The reduction of retrofitting can be confirmed with \texttt{last\_prod\_type\_is\_prod5}.
Product 8 only slightly favours the criticality hypothesis. There is a negative attribution for the \texttt{buffer\_content\_duration\_prod8} which favors to the criticality aspect (compare above). Product 7 favours the criticality hypothesis. Its attribution values were low as well.

\subsubsection{Robustness Checking}
In order to ensure transferability and robustness of our approach, we tested our hypotheses on a different week of production with a different data constellation (only products 4 and 5 were produced). Here, our hypotheses match the DeepSHAP results as well (see \ref{Appendix_SHAP}). For example, if product 5 (\ref{fig:agg5-week42}) was produced last, it is more likely to be produced again (setup efforts hypothesis) and if the buffer content of product 5 is lower or the demand is higher, production of product 5 is more likely (criticality hypothesis).
Input x Gradient does not support these hypotheses, because the attributions yield contrary results because of only two actions. The buffer content duration for product 7 and the buffer content duration for product 2 give conflicting attribution values for products 4 and 5 (inverse correlations). On the later attributions we see the setup efforts hypothesis confirmed for product 4 (\textit{last\_pr\_type\_is\_pr4}) is positive).

\subsubsection{Falsification of Explanations}
We were able to validate the xAI explanations by comparing them to the hypotheses we generated in advance based on domain knowledge. Now, we can present the hypotheses as interpretations of the agent's behavior to the stakeholders, instead of having non-experts in AI inspect dozens of plots and attribution values. The production planners (or management) can then in return give feedback on the plausibility of these explanations.

\subsection{Comparing DeepSHAP and Input x Gradient}
DeepSHAP matched the hypotheses more often in our use case. Using SHAP values, different effects for higher and lower feature values can be inspected, which is not the case for Input x Gradient and very beneficial to gain a deeper understanding in the decision process of the agent. Also, SHAP offers a range of different visualizations that can facilitate understanding. However, in DeepSHAP there are single outliers and unreasonable data points. This method might lead to several hurdles along the way when confronted with variables that are highly dependent. Furthermore, a background dataset has to be chosen; therefore, DeepSHAP is only applicable for use cases that create larger datasets. We conclude that DeepSHAP performs better for classes with many cases (e.g., product 5) and worse for classes with few cases (e.g., product 7). It should also be considered that the concept of Shapley values may be harder to communicate.

Input x Gradient favours the hypotheses less often than DeepSHAP. The interpretation of the explanations is not visibly attractive as in the case of DeepSHAP. Attribution plots can be generated to compare the attribution values for different products and features. It can not be directly compared because the single observations are not visible in the plot like in the SHAP plot. Different gradient attribution approaches are more often used in the context of convolutional NNs. It is harder to use them extensively for tabular data. In the case of the most produced products, attribution values can be computed efficiently and support our findings. In case of the other less produced products like product 7, the attribution values are small (see \ref{Appendix_InputxGradient}) and can thus not be interpreted meaningfully.

Overall, SHAP was more suitable for the given data (RQ 1.2). Generally, it is desirable to be able to interpret all actions of the agent. For Input x Gradient, this was not possible. The dataset was limited to specific actions and several features showed slight attribution for non-produced products. In a practical setting, this may be hard to communicate. SHAP might be the way to go here, because it may provide better explanations. Another approach may be to gather more data, if possible. This would enhance both methods. SHAP's plotting functionality works out of the box and may assist better in finding interpretations.

\subsection{Adapted xAI Workflow}
Using the results and insights we gained by generating explanations for the DRL agent in our use case based on the workflow of \citeA{tchuente2024methodological}, we now adapt said workflow to make it practically feasible for using xAI in the context of production planning (RQ 2.1). We could apply the greyed out phases unfetteredly in this special use case. To apply the whole workflow for explaining DRL agents in a production scheduling context, we made several adjustments.


\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{pictures/Our_Framework.png}
    \caption{Our proposed framework is rooted in \captionciteA{tchuente2024methodological}, but introduces new phases.}
    \label{fig:tchuente_modified}
\end{figure}

\subsubsection{\textbf{Weight Extraction}}
The first novel phase consists of extracting the weights of the network and gathering the available data. This is particularly important, because in RL a direct mapping between states and actions is oftentimes not possible and thus the function is approximated, for example by using NNs. By extracting the weights, we have access to the learned policy.

The approach must be adapted depending on the data available:

\begin{itemize}
    \item If only the raw data of the agent's decision is available and there is no access to model weights or other information regarding the network, it is feasible to train a surrogate model on the data frame. For example, a random forest classifier can be used to model the agent's behaviour. This classifier can then serve as an input for various xAI frameworks. The information gain here is limited, because the agent used a different model.

    \item Generating new weights is also a feasible approach. When only a data frame is available and the net dimensions are clear, one can mimic the network structure and create a new network with the same proportions (\textit{fake network}). Then, use inference on the data frame and describe its new weights with the xAI frameworks. The information gain here is better than in the latter approach although still noisy. In the network, the structure is the same but the weights are different. In the context of post-hoc model agnostic explainers, using different weights is not optimal. This is because ideally, we want to explain the models ``ideas' during the training phase.

    \item When the data, weights and network structure (not the network itself) are at hand, these can be used to generate the explanations. In our use case, this was achieved by the export\_model function of the Ray framework, which was utilized to train the agent \shortcite{moritz2018ray}. If the network has been implemented in PyTorch \shortcite{paszke2019pytorchimperativestylehighperformance}, extracting the weights is not needed. For our use case, we mimicked the network structure in PyTorch and copied the weights from the Ray model. You may extract certain layers to explain specific structures of the net. After this, we loaded the network with the classical \textit{torch.load} command.

    \item If the real network (e.g. not a Ray version), the weights and the raw data is available, you may directly apply the xAI methods on the net.
\end{itemize}

This step ends the data phase.

\subsubsection{\textbf{Hypotheses Generation}}
After we extracted the weights, we can start by formulating hypotheses about the agent's behaviour. For this, we consider causal presumptions based on domain-knowledge and the reward function, as well as inspecting descriptive statistics. This approach works for xRL as well as for other xAI; for cases outside of DRL, the knowledge of the reward function has to be exchanged with other model specific assumptions or be left out.
Hypotheses can be formulated using positive or negative relationships between the variables. It is also possible to construct relationships between hypotheses.
Note that if the reward function is already constructed in an interpretable way \textit{before} training (e.g., by reward decomposition), this will simplify this approach. However, for post-hoc explainabilty, influencing stages before the model was employed is not possible.

\subsubsection{\textbf{xAI Method Selection}}
Once the hypotheses stand, we can choose suitable xAI frameworks and methods identified in the information phase. Randomness may arise in the split of training and test data, the explanation method itself or in the training of the network. Setting seeds in this context is a safe way to achieve fixed explanations.
It is desirable to apply frameworks which cover a wide range of xAI methods. Here, one might apply a model-specific and a model-agnostic xAI method or use local and global explainers. For this step, a cooperation with data scientists might be beneficial. We give an overview of recommendations; however, these are not comprehensive and an analysis on the requirements, constrains, and characteristics of the use case must be performed to find the right explainer:
\begin{enumerate}
    \item Model-specific explainers might be used when debugging is the main goal or when computational costs are high and can be lowered using model-speciﬁc information.
    \item Model-agnostic methods can be utilized when model-specific methods are constructed too narrowly and cannot be applied to complex real-world scenarios.
    \item Local explanations may be incorporated when only single decisions are to be explained.
    \item Global explainers should be used when the behavior of the (entire) model is of interest.

\end{enumerate}
To enhance robustness, it is possible to fit the explainer on different configurations of the network and to use cross validation in the same step \cite{brownecrossval}. After capturing the explanation values, it is important to check for outliers in the generated list of attributions. Also, the attributions may be aggregated using the mean or median. A confidence interval may be fitted to further support the findings \shortcite{napolitano2023learning, pmlr-v238-neuhof24a}. \citeA{napolitano2023learning} for example develop Interval FastSHAP based on Coalition Interval Games and IntervalSHAP. They show that the prediciton quality can be increased by using more predictors.

\subsubsection{\textbf{Falsification}}
Now, we apply the xAI methods and interpret the findings using our hypotheses to verify or falsify the explanations: Do the hypotheses serve as an interpretation of the xAI explanations? If so, the xAI results align with domain knowledge and the hypotheses can be communicated as interpretations of the agent's behavior (green light in Figure \ref{fig:validitycheck}). If explanations and hypotheses do not match, visit the section validity check.

\subsubsection{\textbf{Validity Check}}
The goal here is to inspect inconsistencies between the xAI methods, the hypotheses and the broader context (yellow and red light in Figure \ref{fig:validitycheck}). Investigate where and to what degree there are deviations between the hypotheses and the xAI explanations, then compare both with domain-knowledge and descriptive statics (e.g., the broader context).
\begin{enumerate}
    \item Do the xAI results match the broader context? In this case, you may have missed crucial elements in the hypotheses generation. Improve your hypotheses and retest them, preferably on a new data set.
    \item Do the xAI results still speak against domain-knowledge? If so, you need to double-check the validity of the chosen xAI methods (assumptions, prerequisites, plausibility for the use case) and possibly apply the hypotheses to other xAI methods. If the mismatch between hypotheses and xAI results persists, you may have detected issues in the underlying AI-model and need to consult developers.
\end{enumerate}

To fully cover for the non-deterministic nature of the explanations, we deliver an extension of the proposed framework which highlights how the Validity Check can be characterized:

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{pictures/Verification.drawio.png}
    \caption{The validity check consists of three scenarios ranging from valid hypothesis to partly valid to not valid.}
    \label{fig:validitycheck}
\end{figure}

If the hypotheses align with xAI results, the explanations can be deployed and communicated (Scenario 1; RQ 2.2). The journey is not over here, though. Continuous observation and adaption are crucial.
If the hypotheses are partly valid, consider the descriptive statistics and domain-knowledge gathered before. If these support the results of the xAI methods, you may need to reify the hypotheses.
If the hypotheses do not align with xAI results and you checked them before as well, it is time to either question the validity of the used xAI method or revise the AI-model itself. Here, you may need to consult domain-experts and developers.

The proposed framework is generic in the sense that it can be applied in various business scenarios involving xAI. Although, it suffers from several limitations.

\subsection{Limitations and Future Research}
As long as AI remains an ever advancing technology, xAI will play an important role. Our proposed framework shows how to approach xRL in a production scheduling setting.
However, this approach still involves experts manually constructing and comparing the hypotheses to the explanations.

First of all, the way hypotheses generation is approached needs to be formalized.
There is the need to define objective, transparent criteria for the determinants understandability, comparability, communicability, transferability, and validability of hypotheses in any scenario. The question of the ``ideal' hypothesis still persists, because this is a highly complex question. Different factors from various scientific disciplines play a role here. Ideality is a subjective question.

Second of all, precise rules to identify significant deviations from the hypotheses are lacking, which might be constructed similarly to hypotheses testing in statistics. This would be needed so that ideally the agent may be able to self-explain.

Thirdly, we were not able to use the original custom class NN with the xAI methods and had to rebuild it, thereby introducing some noise. There were 5 cases, where our rebuild network did not match the predictions of the original one.
While we are inspecting overall patterns, there were individual cases where effects were inconsistent with our hypotheses. Additionally, as discussed in the literature review, there were few unrealistic points in the SHAP plots, most likely due to feature dependence.

In the future, it could be promising to create a self-explaining AI using our hypotheses-based approach. An application that adjusts the type of explanation to the needs of the explainee in a conversational or interactive style might be beneficial to increase understanding. Here, it might be fruitful to employ large language models. Additionally, future research should focus on evaluating the explanations and putting the human – the explainee – in the foreground. Our paper focuses on creating explanations and interpretations, but these should also be tested and adapted in terms of effectiveness, user satisfaction, and trust, which requires studies involving humans and a collaboration with social and cognitive science. \shortcite{kim2021multi,mohseni202124, milani2024explainable}

Also, quantitative metrics to evaluate xRL methods, f.e. regarding their fidelity, are lacking in literature \shortcite{milani2024explainable, xiong2024xrl} and were also not assessed in this paper. In the future, these types of metrics should be included.

The framework does not cover details of approaching stakeholders. There may be several blockades to overcome when communicating xAI. These blockades may be gridlocked opinions in the company, a lack of authority or a lack of productive capital to implement suggested changes (social proof, authority, scarcity; c.f. \shortcite{cialdini2001science}). This should also anticipate human biases and heuristics of thought \shortcite{tversky1974judgment}. Humans prefer explanations which intuitively make sense to them and which align with their world view \shortcite{gentner2014mental}. Workflows should reflect on that to create explanations that are transparent and ready to communicate to third parties \shortcite{riveiro2021s}.

Our workflow has not yet been tested in other production and manufacturing settings (e.g. the chemical industry), which could be an opportunity for future research. Also, the framework is data-driven and will be hard to implement when available data is scarce.

Lastly, using our hypotheses approach, we consider the causal understanding in the production planning context. However, the xAI methods themselves are primarily of correlative nature and thus cannot provide evidence for causal effects.